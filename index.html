<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>YOLOv8 Demo</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>
  <style>
    video, canvas {
      width: 640px;
      height: 480px;
      border: 1px solid #333;
    }
    #controls {
      margin: 10px 0;
    }
  </style>
</head>
<body>
  <h1>YOLOv8 Demo</h1>
  <div id="controls">
    <button id="switchCamera">切换摄像头</button>
  </div>
  <video id="video" autoplay muted></video>
  <canvas id="canvas"></canvas>

  <script>
    let currentCamera = 'user'; // 默认前置摄像头
    let videoStream = null;
    let model = null;

    async function initCamera(camera = 'user') {
      const video = document.getElementById('video');
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop());
      }
      try {
        videoStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: camera } });
        video.srcObject = videoStream;
        return new Promise(resolve => {
          video.onloadedmetadata = () => {
            video.play();
            resolve(video);
          };
        });
      } catch (err) {
        alert('摄像头访问失败：' + err);
      }
    }

    async function loadModel() {
      const modelUrl = 'https://hyuto.github.io/yolov8-tfjs/yolov8n_web_model/model.json';
      const loadedModel = await tf.loadGraphModel(modelUrl);
      console.log('Model loaded:', loadedModel);
      return loadedModel;
    }

    function drawPredictions(predictions, canvas, video) {
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      ctx.strokeStyle = 'red';
      ctx.lineWidth = 2;
      ctx.font = '18px Arial';
      ctx.fillStyle = 'red';

      predictions.forEach(pred => {
        const [x, y, w, h] = pred.bbox;
        ctx.strokeRect(x, y, w, h);
        ctx.fillText(`${pred.class} ${(pred.score*100).toFixed(1)}%`, x, y > 10 ? y-5 : 10);
      });
    }

    async function runDetection(video, model, canvas) {
      const inputTensor = tf.browser.fromPixels(video)
        .resizeBilinear([640, 640])
        .div(255)
        .expandDims(0);

      const output = await model.executeAsync(inputTensor);

      // YOLOv8 TF.js 输出解析
      // output 是字典: {boxes, scores, classes, valid_detections}
      const boxes = output['boxes'].arraySync();        // [num_boxes,4]
      const scores = output['scores'].arraySync();      // [num_boxes]
      const classes = output['classes'].arraySync();    // [num_boxes]
      const numDetections = output['num_detections'].dataSync()[0];

      const predictions = [];
      for (let i = 0; i < numDetections; i++) {
        if (scores[i] > 0.3) {
          const [x1, y1, x2, y2] = boxes[i];
          predictions.push({
            bbox: [
              x1 * video.videoWidth,
              y1 * video.videoHeight,
              (x2 - x1) * video.videoWidth,
              (y2 - y1) * video.videoHeight
            ],
            score: scores[i],
            class: classes[i].toString()
          });
        }
      }

      drawPredictions(predictions, canvas, video);
      inputTensor.dispose();
      Object.values(output).forEach(t => t.dispose());
    }

    async function runDemo() {
      const video = await initCamera(currentCamera);
      const canvas = document.getElementById('canvas');
      model = await loadModel();

      async function detectLoop() {
        await runDetection(video, model, canvas);
        requestAnimationFrame(detectLoop);
      }
      detectLoop();
    }

    // 切换摄像头按钮
    document.getElementById('switchCamera').onclick = async () => {
      currentCamera = currentCamera === 'user' ? 'environment' : 'user';
      await initCamera(currentCamera);
    };

    window.onload = runDemo;
  </script>
</body>
</html>
