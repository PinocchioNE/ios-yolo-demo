<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>YOLOv8 Demo</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>
  <style>
    video, canvas {
      width: 640px;
      height: 480px;
      border: 1px solid #333;
    }
  </style>
</head>
<body>
  <h1>YOLOv8 Demo</h1>
  <video id="video" autoplay muted></video>
  <canvas id="canvas"></canvas>

  <script>
    async function initCamera() {
      const video = document.getElementById('video');
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        return new Promise(resolve => {
          video.onloadedmetadata = () => {
            video.play();
            resolve(video);
          };
        });
      } catch (err) {
        alert('摄像头访问失败：' + err);
      }
    }

    async function loadModel() {
      // 在线可访问的 YOLOv8n TF.js 模型
      const modelUrl = 'https://hyuto.github.io/yolov8-tfjs/yolov8n_web_model/model.json';
      const model = await tf.loadGraphModel(modelUrl);
      console.log('Model loaded:', model);
      return model;
    }

    function drawPredictions(predictions, canvas, video) {
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      ctx.strokeStyle = 'red';
      ctx.lineWidth = 2;
      ctx.font = '18px Arial';
      ctx.fillStyle = 'red';

      predictions.forEach(pred => {
        const [x, y, w, h] = pred.bbox;
        ctx.strokeRect(x, y, w, h);
        ctx.fillText(`${pred.class} ${(pred.score*100).toFixed(1)}%`, x, y > 10 ? y-5 : 10);
      });
    }

    async function runDetection(video, model, canvas) {
      const inputTensor = tf.browser.fromPixels(video).resizeBilinear([640, 640]).div(255).expandDims(0);
      const output = await model.executeAsync(inputTensor);

      // YOLOv8 输出处理
      const boxes = output[0].arraySync(); // [num_boxes, 4]
      const scores = output[1].arraySync(); // [num_boxes]
      const classes = output[2].arraySync(); // [num_boxes]

      const predictions = [];
      for (let i = 0; i < boxes.length; i++) {
        if (scores[i] > 0.3) { // 阈值
          const [x1, y1, x2, y2] = boxes[i];
          predictions.push({
            bbox: [
              x1 * video.videoWidth,
              y1 * video.videoHeight,
              (x2 - x1) * video.videoWidth,
              (y2 - y1) * video.videoHeight
            ],
            score: scores[i],
            class: classes[i].toString()
          });
        }
      }

      drawPredictions(predictions, canvas, video);
      inputTensor.dispose();
      output.forEach(t => t.dispose());
    }

    async function runDemo() {
      const video = await initCamera();
      const canvas = document.getElementById('canvas');
      const model = await loadModel();

      // 每帧检测
      async function detectLoop() {
        await runDetection(video, model, canvas);
        requestAnimationFrame(detectLoop);
      }
      detectLoop();
    }

    window.onload = runDemo;
  </script>
</body>
</html>
