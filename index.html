<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>YOLOv8 TF.js Demo</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>
  <style>
    video, canvas {
      width: 640px;
      height: 480px;
      border: 1px solid #333;
      display: block;
      margin-bottom: 10px;
    }
    button {
      margin-bottom: 10px;
    }
  </style>
</head>
<body>
  <h1>YOLOv8 TF.js Demo</h1>

  <button id="switchBtn">切换摄像头</button>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>

  <script>
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvas');
    let ctx = canvas.getContext('2d');
    let currentCamera = 'user'; // 'user' 前摄像头, 'environment' 后摄像头
    let stream = null;
    let model = null;

    async function startCamera() {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: currentCamera }
      });
      video.srcObject = stream;
    }

    document.getElementById('switchBtn').addEventListener('click', async () => {
      currentCamera = currentCamera === 'user' ? 'environment' : 'user';
      await startCamera();
    });

    async function loadModel() {
      console.log('加载模型...');
      model = await tf.loadGraphModel('https://hyuto.github.io/yolov8-tfjs/yolov8n_web_model/model.json');
      console.log('模型加载完成', model);
    }

    function drawPredictions(predictions) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 2;
      ctx.font = '16px Arial';
      ctx.strokeStyle = 'red';
      ctx.fillStyle = 'red';

      predictions.forEach(p => {
        const [x, y, w, h] = p.bbox;
        ctx.strokeRect(x, y, w, h);
        ctx.fillText(`${p.class} ${p.score.toFixed(2)}`, x, y > 10 ? y - 5 : y + 15);
      });
    }

    async function runDetection() {
      if (!model) return;

      const inputTensor = tf.browser.fromPixels(video)
        .resizeBilinear([640, 640])
        .div(255)
        .expandDims(0);

      try {
        const output = await model.executeAsync(inputTensor);
        const data = output.arraySync()[0]; // shape: [N,6]

        const predictions = [];
        for (let i = 0; i < data.length; i++) {
          const [x, y, w, h, score, classId] = data[i];
          if (score > 0.3) {
            predictions.push({
              bbox: [x * video.videoWidth, y * video.videoHeight, w * video.videoWidth, h * video.videoHeight],
              score: score,
              class: classId.toString()
            });
          }
        }

        drawPredictions(predictions);
      } catch (err) {
        console.error('模型预测失败:', err);
      } finally {
        inputTensor.dispose();
        if (Array.isArray(output)) output.forEach(t => t.dispose());
        else output.dispose();
      }

      requestAnimationFrame(runDetection);
    }

    async function init() {
      await startCamera();
      await loadModel();
      runDetection();
    }

    init();
  </script>
</body>
</html>
