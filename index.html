<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>YOLOv8 TF.js Demo</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>
  <style>
    video, canvas {
      width: 640px;
      height: 480px;
      border: 1px solid #333;
    }
  </style>
</head>
<body>
  <h1>YOLOv8 TF.js Demo</h1>
  <video id="video" autoplay muted></video>
  <canvas id="canvas"></canvas>

  <script>
    async function initCamera() {
      const video = document.getElementById('video');
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        video.srcObject = stream;
        return new Promise(resolve => {
          video.onloadedmetadata = () => {
            video.play();
            resolve(video);
          };
        });
      } catch (err) {
        alert('摄像头访问失败：' + err);
      }
    }

    async function loadModel() {
      const modelUrl = 'https://hyuto.github.io/yolov8-tfjs/yolov8n_web_model/model.json';
      const model = await tf.loadGraphModel(modelUrl);
      console.log('Model loaded:', model);
      return model;
    }

    function drawPredictions(predictions, canvas, video) {
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      ctx.strokeStyle = 'red';
      ctx.lineWidth = 2;
      ctx.font = '16px Arial';
      ctx.fillStyle = 'red';

      predictions.forEach(pred => {
        const [x, y, w, h] = pred.bbox;
        ctx.strokeRect(x, y, w, h);
        ctx.fillText(`${pred.class} ${(pred.score*100).toFixed(1)}%`, x, y > 10 ? y-5 : 10);
      });
    }

    async function runDemo() {
      const video = await initCamera();
      const canvas = document.getElementById('canvas');
      const model = await loadModel();

      async function detectFrame() {
        tf.engine().startScope();

        // 把 video 转成 Tensor
        const imgTensor = tf.browser.fromPixels(video).expandDims(0).toFloat().div(255.0);

        // 调用模型
        const outputs = await model.executeAsync(imgTensor);

        // YOLOv8 TF.js 输出解析，可能包含 boxes, scores, classes
        // 假设 outputs[0]=boxes, outputs[1]=scores, outputs[2]=classIds
        const boxes = outputs[0].arraySync()[0];      // [N,4] -> [x1,y1,x2,y2]
        const scores = outputs[1].arraySync()[0];     // [N]
        const classes = outputs[2].arraySync()[0];    // [N]

        const predictions = [];
        for(let i=0; i<scores.length; i++){
          if(scores[i] > 0.3){ // 阈值，可调
            const [x1,y1,x2,y2] = boxes[i];
            predictions.push({
              bbox: [x1, y1, x2-x1, y2-y1],
              class: classes[i].toString(),
              score: scores[i]
            });
          }
        }

        drawPredictions(predictions, canvas, video);

        tf.engine().endScope();
        requestAnimationFrame(detectFrame);
      }

      detectFrame();
    }

    window.onload = runDemo;
  </script>
</body>
</html>
