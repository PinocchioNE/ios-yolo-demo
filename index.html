<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8 TensorFlow.js Demo - Fixed Version</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }
        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s;
        }
        .btn-primary {
            background-color: #007bff;
            color: white;
        }
        .btn-primary:hover {
            background-color: #0056b3;
        }
        .btn-secondary {
            background-color: #6c757d;
            color: white;
        }
        .btn-secondary:hover {
            background-color: #545b62;
        }
        .btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        .video-container {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }
        .video-wrapper {
            position: relative;
            border: 2px solid #ddd;
            border-radius: 8px;
            overflow: hidden;
        }
        .video-wrapper h3 {
            margin: 0 0 10px 0;
            text-align: center;
            color: #333;
        }
        #video, #outputCanvas {
            display: block;
            max-width: 100%;
            height: auto;
        }
        .info-panel {
            background: #f8f9fa;
            border-radius: 5px;
            padding: 15px;
            margin-top: 20px;
        }
        .info-row {
            display: flex;
            justify-content: space-between;
            margin-bottom: 10px;
        }
        .info-row:last-child {
            margin-bottom: 0;
        }
        .status {
            padding: 8px 15px;
            border-radius: 20px;
            font-size: 12px;
            font-weight: bold;
            text-align: center;
            margin-bottom: 15px;
        }
        .status.loading {
            background-color: #fff3cd;
            color: #856404;
        }
        .status.ready {
            background-color: #d4edda;
            color: #155724;
        }
        .status.error {
            background-color: #f8d7da;
            color: #721c24;
        }
        .detection-info {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 10px;
            margin-top: 10px;
            border-radius: 0 5px 5px 0;
        }
        .settings {
            background: #f0f0f0;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .settings h3 {
            margin-top: 0;
        }
        .setting-group {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 10px;
        }
        .setting-group label {
            min-width: 120px;
        }
        input[type="range"] {
            flex: 1;
            max-width: 200px;
        }
        .value-display {
            min-width: 50px;
            font-weight: bold;
        }
        @media (max-width: 768px) {
            .video-container {
                flex-direction: column;
                align-items: center;
            }
            .controls {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>YOLOv8 TensorFlow.js Demo - Fixed Version</h1>
            <p>实时目标检测 - 优化版本</p>
        </div>

        <div class="status" id="status">正在初始化...</div>

        <div class="settings">
            <h3>检测设置</h3>
            <div class="setting-group">
                <label>置信度阈值:</label>
                <input type="range" id="confidenceSlider" min="0.1" max="0.9" step="0.05" value="0.25">
                <span class="value-display" id="confidenceValue">0.25</span>
            </div>
            <div class="setting-group">
                <label>NMS阈值:</label>
                <input type="range" id="nmsSlider" min="0.1" max="0.9" step="0.05" value="0.45">
                <span class="value-display" id="nmsValue">0.45</span>
            </div>
            <div class="setting-group">
                <label>最大检测数:</label>
                <input type="range" id="maxDetectionsSlider" min="5" max="50" step="5" value="20">
                <span class="value-display" id="maxDetectionsValue">20</span>
            </div>
        </div>

        <div class="controls">
            <button class="btn btn-primary" id="startBtn">开启摄像头</button>
            <button class="btn btn-secondary" id="stopBtn" disabled>停止检测</button>
            <button class="btn btn-secondary" id="captureBtn" disabled>截图保存</button>
        </div>

        <div class="video-container">
            <div class="video-wrapper">
                <h3>摄像头输入</h3>
                <video id="video" width="640" height="480" autoplay muted playsinline></video>
            </div>
            <div class="video-wrapper">
                <h3>检测结果</h3>
                <canvas id="outputCanvas" width="640" height="480"></canvas>
            </div>
        </div>

        <div class="info-panel">
            <div class="info-row">
                <span><strong>模型状态:</strong></span>
                <span id="modelStatus">未加载</span>
            </div>
            <div class="info-row">
                <span><strong>检测FPS:</strong></span>
                <span id="fps">0</span>
            </div>
            <div class="info-row">
                <span><strong>处理时间:</strong></span>
                <span id="processTime">0ms</span>
            </div>
            <div class="info-row">
                <span><strong>检测到的对象:</strong></span>
                <span id="detectionCount">0</span>
            </div>
            <div class="detection-info" id="detectionInfo" style="display: none;">
                <strong>检测详情:</strong>
                <div id="detectionDetails"></div>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <script>
        // COCO数据集类别名称
        const classNames = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
            'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
            'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
            'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
            'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ];

        // 全局变量
        let model = null;
        let video = null;
        let canvas = null;
        let ctx = null;
        let isDetecting = false;
        let animationId = null;
        let lastTime = 0;
        let frameCount = 0;
        let fpsStartTime = Date.now();

        // 检测参数
        let confidenceThreshold = 0.25;
        let nmsThreshold = 0.45;
        let maxDetections = 20;

        // DOM元素
        const statusEl = document.getElementById('status');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const captureBtn = document.getElementById('captureBtn');
        const modelStatusEl = document.getElementById('modelStatus');
        const fpsEl = document.getElementById('fps');
        const processTimeEl = document.getElementById('processTime');
        const detectionCountEl = document.getElementById('detectionCount');
        const detectionInfoEl = document.getElementById('detectionInfo');
        const detectionDetailsEl = document.getElementById('detectionDetails');

        // 设置控件
        const confidenceSlider = document.getElementById('confidenceSlider');
        const nmsSlider = document.getElementById('nmsSlider');
        const maxDetectionsSlider = document.getElementById('maxDetectionsSlider');
        const confidenceValue = document.getElementById('confidenceValue');
        const nmsValue = document.getElementById('nmsValue');
        const maxDetectionsValue = document.getElementById('maxDetectionsValue');

        // 初始化
        async function init() {
            try {
                updateStatus('正在加载模型...', 'loading');
                
                // 加载YOLOv8模型
                const modelUrl = 'https://pinocchione.github.io/ios-yolo-demo/yolov8n_web_model/model.json';
                model = await tf.loadGraphModel(modelUrl);
                
                updateStatus('模型加载成功', 'ready');
                modelStatusEl.textContent = '已加载';
                startBtn.disabled = false;
                
                console.log('模型加载成功');
                console.log('模型输入形状:', model.inputs[0].shape);
                console.log('模型输出形状:', model.outputs.map(output => output.shape));
                
            } catch (error) {
                console.error('模型加载失败:', error);
                updateStatus('模型加载失败: ' + error.message, 'error');
                modelStatusEl.textContent = '加载失败';
            }
        }

        // 更新状态显示
        function updateStatus(message, type = 'loading') {
            statusEl.textContent = message;
            statusEl.className = `status ${type}`;
        }

        // 设置摄像头
        async function setupCamera() {
            try {
                video = document.getElementById('video');
                canvas = document.getElementById('outputCanvas');
                ctx = canvas.getContext('2d');

                // 获取摄像头权限和流
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'environment' // 优先使用后置摄像头
                    },
                    audio: false
                });

                video.srcObject = stream;
                
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        // 获取视频的实际尺寸
                        const videoWidth = video.videoWidth;
                        const videoHeight = video.videoHeight;
                        
                        console.log(`视频实际尺寸: ${videoWidth}x${videoHeight}`);
                        
                        // 设置显示尺寸，保持宽高比
                        const maxDisplayWidth = 640;
                        const maxDisplayHeight = 480;
                        
                        let displayWidth, displayHeight;
                        const videoAspect = videoWidth / videoHeight;
                        const displayAspect = maxDisplayWidth / maxDisplayHeight;
                        
                        if (videoAspect > displayAspect) {
                            displayWidth = maxDisplayWidth;
                            displayHeight = maxDisplayWidth / videoAspect;
                        } else {
                            displayHeight = maxDisplayHeight;
                            displayWidth = maxDisplayHeight * videoAspect;
                        }
                        
                        // 设置video和canvas的显示尺寸
                        video.style.width = displayWidth + 'px';
                        video.style.height = displayHeight + 'px';
                        canvas.style.width = displayWidth + 'px';
                        canvas.style.height = displayHeight + 'px';
                        
                        // 设置canvas的实际尺寸为640x640（模型输入尺寸）
                        canvas.width = 640;
                        canvas.height = 640;
                        
                        resolve();
                    };
                });
            } catch (error) {
                console.error('摄像头设置失败:', error);
                updateStatus('摄像头访问失败: ' + error.message, 'error');
                throw error;
            }
        }

        // 预处理图像 - 修复版本
        function preprocessImage(video) {
            // 创建临时canvas用于预处理
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            
            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;
            
            // 计算中心裁剪区域
            const size = Math.min(videoWidth, videoHeight);
            const startX = (videoWidth - size) / 2;
            const startY = (videoHeight - size) / 2;
            
            // 设置临时canvas尺寸为640x640
            tempCanvas.width = 640;
            tempCanvas.height = 640;
            
            // 从视频中心裁剪正方形区域并缩放到640x640
            tempCtx.drawImage(
                video,
                startX, startY, size, size,  // 源区域（中心正方形）
                0, 0, 640, 640               // 目标区域（640x640）
            );
            
            // 获取图像数据并转换为tensor
            const imageData = tempCtx.getImageData(0, 0, 640, 640);
            const tensor = tf.browser.fromPixels(imageData)
                .expandDims(0)
                .div(255.0);
            
            return {
                tensor,
                cropInfo: { startX, startY, size, videoWidth, videoHeight }
            };
        }

        // 坐标转换 - 修复版本
        function convertCoordinates(x, y, width, height, cropInfo) {
            const { startX, startY, size, videoWidth, videoHeight } = cropInfo;
            
            // 从640x640坐标转换回裁剪区域坐标
            const cropX = (x / 640) * size;
            const cropY = (y / 640) * size;
            const cropW = (width / 640) * size;
            const cropH = (height / 640) * size;
            
            // 转换到原始视频坐标
            const videoX = cropX + startX;
            const videoY = cropY + startY;
            
            // 转换到canvas显示坐标
            const canvasX = (videoX / videoWidth) * 640;
            const canvasY = (videoY / videoHeight) * 640;
            const canvasW = (cropW / videoWidth) * 640;
            const canvasH = (cropH / videoHeight) * 640;
            
            return { x: canvasX, y: canvasY, width: canvasW, height: canvasH };
        }

        // 非极大值抑制
        function nms(boxes, scores, classes, maxOutputSize, iouThreshold) {
            const indices = tf.image.nonMaxSuppression(
                boxes, scores, maxOutputSize, iouThreshold
            );
            return indices;
        }

        // 执行检测
        async function detect() {
            if (!model || !video || video.readyState !== 4) return;

            const startTime = performance.now();

            try {
                // 预处理图像
                const { tensor: input, cropInfo } = preprocessImage(video);

                // 模型推理
                const predictions = await model.executeAsync(input);
                
                // 处理输出
                let boxes, scores, classes;
                
                if (Array.isArray(predictions)) {
                    // 多输出格式
                    [boxes, scores, classes] = predictions;
                } else {
                    // 单输出格式 - YOLOv8通常是这种格式
                    const output = predictions;
                    const outputData = await output.data();
                    const outputShape = output.shape;
                    
                    console.log('模型输出形状:', outputShape);
                    console.log('输出数据长度:', outputData.length);
                    
                    // YOLOv8输出格式: [1, 84, 8400] 或类似
                    // 84 = 4(bbox) + 80(classes)
                    const numDetections = outputShape[2]; // 8400
                    const numClasses = outputShape[1] - 4; // 80
                    
                    const boxesData = [];
                    const scoresData = [];
                    const classesData = [];
                    
                    for (let i = 0; i < numDetections; i++) {
                        // 获取边界框坐标 (cx, cy, w, h)
                        const cx = outputData[i];
                        const cy = outputData[numDetections + i];
                        const w = outputData[2 * numDetections + i];
                        const h = outputData[3 * numDetections + i];
                        
                        // 转换为 (x1, y1, x2, y2)
                        const x1 = cx - w / 2;
                        const y1 = cy - h / 2;
                        const x2 = cx + w / 2;
                        const y2 = cy + h / 2;
                        
                        // 获取类别概率
                        let maxScore = 0;
                        let maxClass = 0;
                        
                        for (let j = 0; j < numClasses; j++) {
                            const score = outputData[(4 + j) * numDetections + i];
                            if (score > maxScore) {
                                maxScore = score;
                                maxClass = j;
                            }
                        }
                        
                        // 只保留置信度高于阈值的检测
                        if (maxScore > confidenceThreshold) {
                            boxesData.push([y1, x1, y2, x2]); // TensorFlow格式: [y1, x1, y2, x2]
                            scoresData.push(maxScore);
                            classesData.push(maxClass);
                        }
                    }
                    
                    if (boxesData.length > 0) {
                        boxes = tf.tensor2d(boxesData);
                        scores = tf.tensor1d(scoresData);
                        classes = tf.tensor1d(classesData, 'int32');
                    } else {
                        boxes = tf.zeros([0, 4]);
                        scores = tf.zeros([0]);
                        classes = tf.zeros([0], 'int32');
                    }
                }

                // 应用NMS
                let selectedIndices;
                if (scores.shape[0] > 0) {
                    selectedIndices = await nms(
                        boxes, scores, classes, 
                        maxDetections, nmsThreshold
                    );
                } else {
                    selectedIndices = tf.tensor1d([], 'int32');
                }

                // 获取最终结果
                const selectedIndicesData = await selectedIndices.data();
                const boxesData = await boxes.data();
                const scoresData = await scores.data();
                const classesData = await classes.data();

                // 清空画布
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                // 绘制视频帧到canvas
                const videoWidth = video.videoWidth;
                const videoHeight = video.videoHeight;
                const size = Math.min(videoWidth, videoHeight);
                const startX = (videoWidth - size) / 2;
                const startY = (videoHeight - size) / 2;
                
                ctx.drawImage(
                    video,
                    startX, startY, size, size,
                    0, 0, 640, 640
                );

                // 绘制检测结果
                const detections = [];
                for (let i = 0; i < selectedIndicesData.length; i++) {
                    const idx = selectedIndicesData[i];
                    const score = scoresData[idx];
                    const classId = classesData[idx];
                    const className = classNames[classId] || `Class ${classId}`;
                    
                    // 获取边界框坐标 (TensorFlow格式: [y1, x1, y2, x2])
                    const y1 = boxesData[idx * 4] * 640;
                    const x1 = boxesData[idx * 4 + 1] * 640;
                    const y2 = boxesData[idx * 4 + 2] * 640;
                    const x2 = boxesData[idx * 4 + 3] * 640;
                    
                    const width = x2 - x1;
                    const height = y2 - y1;
                    
                    // 绘制边界框
                    ctx.strokeStyle = '#00ff00';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(x1, y1, width, height);
                    
                    // 绘制标签背景
                    const label = `${className}: ${(score * 100).toFixed(1)}%`;
                    ctx.font = '14px Arial';
                    const textWidth = ctx.measureText(label).width;
                    
                    ctx.fillStyle = 'rgba(0, 255, 0, 0.8)';
                    ctx.fillRect(x1, y1 - 25, textWidth + 10, 25);
                    
                    // 绘制标签文字
                    ctx.fillStyle = 'black';
                    ctx.fillText(label, x1 + 5, y1 - 8);
                    
                    detections.push({
                        class: className,
                        confidence: score,
                        bbox: { x: x1, y: y1, width, height }
                    });
                }

                // 更新检测信息
                updateDetectionInfo(detections);

                // 清理tensor
                input.dispose();
                if (Array.isArray(predictions)) {
                    predictions.forEach(tensor => tensor.dispose());
                } else {
                    predictions.dispose();
                }
                boxes.dispose();
                scores.dispose();
                classes.dispose();
                selectedIndices.dispose();

            } catch (error) {
                console.error('检测过程出错:', error);
            }

            // 更新性能信息
            const endTime = performance.now();
            const processTime = endTime - startTime;
            processTimeEl.textContent = `${processTime.toFixed(1)}ms`;
            
            // 计算FPS
            frameCount++;
            const currentTime = Date.now();
            if (currentTime - fpsStartTime >= 1000) {
                const fps = frameCount / ((currentTime - fpsStartTime) / 1000);
                fpsEl.textContent = fps.toFixed(1);
                frameCount = 0;
                fpsStartTime = currentTime;
            }
        }

        // 更新检测信息显示
        function updateDetectionInfo(detections) {
            detectionCountEl.textContent = detections.length;
            
            if (detections.length > 0) {
                detectionInfoEl.style.display = 'block';
                const details = detections.map(det => 
                    `${det.class} (${(det.confidence * 100).toFixed(1)}%)`
                ).join(', ');
                detectionDetailsEl.textContent = details;
            } else {
                detectionInfoEl.style.display = 'none';
            }
        }

        // 检测循环
        async function detectLoop() {
            if (isDetecting) {
                await detect();
                animationId = requestAnimationFrame(detectLoop);
            }
        }

        // 开始检测
        async function startDetection() {
            try {
                updateStatus('正在启动摄像头...', 'loading');
                await setupCamera();
                
                isDetecting = true;
                updateStatus('检测中...', 'ready');
                
                startBtn.disabled = true;
                stopBtn.disabled = false;
                captureBtn.disabled = false;
                
                detectLoop();
                
            } catch (error) {
                console.error('启动检测失败:', error);
                updateStatus('启动失败: ' + error.message, 'error');
            }
        }

        // 停止检测
        function stopDetection() {
            isDetecting = false;
            
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
            
            if (video && video.srcObject) {
                const tracks = video.srcObject.getTracks();
                tracks.forEach(track => track.stop());
                video.srcObject = null;
            }
            
            updateStatus('已停止检测', 'ready');
            
            startBtn.disabled = false;
            stopBtn.disabled = true;
            captureBtn.disabled = true;
            
            // 清空显示
            if (ctx) {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }
            fpsEl.textContent = '0';
            processTimeEl.textContent = '0ms';
            detectionCountEl.textContent = '0';
            detectionInfoEl.style.display = 'none';
        }

        // 截图保存
        function captureImage() {
            if (!canvas) return;
            
            const link = document.createElement('a');
            link.download = `detection_${new Date().getTime()}.png`;
            link.href = canvas.toDataURL();
            link.click();
        }

        // 设置控件事件监听
        confidenceSlider.addEventListener('input', (e) => {
            confidenceThreshold = parseFloat(e.target.value);
            confidenceValue.textContent = confidenceThreshold.toFixed(2);
        });

        nmsSlider.addEventListener('input', (e) => {
            nmsThreshold = parseFloat(e.target.value);
            nmsValue.textContent = nmsThreshold.toFixed(2);
        });

        maxDetectionsSlider.addEventListener('input', (e) => {
            maxDetections = parseInt(e.target.value);
            maxDetectionsValue.textContent = maxDetections;
        });

        // 按钮事件监听
        startBtn.addEventListener('click', startDetection);
        stopBtn.addEventListener('click', stopDetection);
        captureBtn.addEventListener('click', captureImage);

        // 页面加载完成后初始化
        window.addEventListener('load', init);

        // 页面卸载时清理资源
        window.addEventListener('beforeunload', () => {
            if (isDetecting) {
                stopDetection();
            }
        });
    </script>
</body>
</html>
