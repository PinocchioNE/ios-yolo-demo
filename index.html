<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>YOLOv8 TF.js Demo</title>
<style>
  video, canvas { border: 1px solid black; }
</style>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0/dist/tf.min.js"></script>
</head>
<body>
<h2>YOLOv8 TF.js Demo</h2>
<button id="switchBtn">切换摄像头</button>
<br><br>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script>
window.onload = async () => {
  let model;
  let video = document.getElementById('video');
  let canvas = document.getElementById('canvas');
  let ctx = canvas.getContext('2d');
  let useFrontCamera = false; 
  let currentStream;

  // 类别名，可根据模型自己改
  const classNames = ["person","bicycle","car","motorbike","aeroplane","bus","train","truck","boat","traffic light"];

  // 加载模型
  async function loadModel() {
    model = await tf.loadGraphModel('https://pinocchione.github.io/ios-yolo-demo/yolov8n_web_model/model.json');
    console.log('模型加载完成');
  }

  // 启动摄像头
  async function startCamera() {
    if (currentStream) {
      currentStream.getTracks().forEach(track => track.stop());
    }
    const constraints = { audio: false, video: { facingMode: useFrontCamera ? 'user' : 'environment' } };
    currentStream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = currentStream;

    video.onloadedmetadata = () => {
      video.play();
      canvas.width = 640;
      canvas.height = 640;
      detectFrame();
    };
  }

  document.getElementById('switchBtn').addEventListener('click', () => {
    useFrontCamera = !useFrontCamera;
    startCamera();
  });

  async function detectFrame() {
    if (!model) return requestAnimationFrame(detectFrame);

    tf.engine().startScope();

    // 视频 -> tensor
    let input = tf.browser.fromPixels(video)
                  .resizeBilinear([640, 640])
                  .expandDims(0)
                  .toFloat();

    // 推理
    const outputs = await model.executeAsync({x: input});
    const data = outputs.arraySync(); // [N,6]: x1,y1,x2,y2,score,class

    // 清空画布
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, 640, 640);

    // 绘制检测框
    for (let i=0; i<data.length; i++) {
      let [x1, y1, x2, y2, score, cls] = data[i];
      if (score < 0.3) continue; // 置信度阈值

      // 坐标转换为像素
      x1 *= canvas.width; x2 *= canvas.width;
      y1 *= canvas.height; y2 *= canvas.height;

      // 框
      ctx.strokeStyle = 'red';
      ctx.lineWidth = 2;
      ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

      // 标签
      ctx.fillStyle = 'red';
      ctx.font = '18px Arial';
      const label = `${classNames[cls] || cls} ${(score*100).toFixed(1)}%`;
      ctx.fillText(label, x1, y1>20?y1-5:y1+20);
    }

    tf.engine().endScope();
    requestAnimationFrame(detectFrame);
  }

  await loadModel();
  await startCamera();
};
</script>
</body>
</html>
